{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1iW7pcW3qg7uCrEvFypSfTYGPZgB06b7m","timestamp":1734406157963}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Text Classification (AI or Human Written) with Word2Vec and Machine Learning Models"],"metadata":{"id":"sFDzq_AwMmPV"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uvtsIdqSCgW","executionInfo":{"status":"ok","timestamp":1738289439438,"user_tz":-345,"elapsed":27268,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}},"outputId":"ffcb5a0e-7c79-4a2d-ec0d-560090a46be7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Importing necessary libraries"],"metadata":{"id":"fjrDNSiFMbYw"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from gensim.models import Word2Vec\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import re\n","import joblib\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.naive_bayes import MultinomialNB"],"metadata":{"id":"K-oo-mp_Kdwc","executionInfo":{"status":"ok","timestamp":1738293162488,"user_tz":-345,"elapsed":651,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Defining file paths for the training and testing datasets stored on Google Drive.\n"],"metadata":{"id":"e79aoatiS4nl"}},{"cell_type":"code","source":["train_path=\"/content/drive/MyDrive/AI_Content_Detector/updated_dataset/train_df.csv\"\n","test_path =\"/content/drive/MyDrive/AI_Content_Detector/updated_dataset/test_df.csv\""],"metadata":{"id":"RPs01OP_5WA_","executionInfo":{"status":"ok","timestamp":1738293170710,"user_tz":-345,"elapsed":443,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# Load  datasets\n"],"metadata":{"id":"4fxttPOETB0e"}},{"cell_type":"code","source":["train_df = pd.read_csv(train_path)\n","test_df = pd.read_csv(test_path)"],"metadata":{"id":"4QfO2vIX5fFb","executionInfo":{"status":"ok","timestamp":1738293173286,"user_tz":-345,"elapsed":421,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Splitting the dataset into features (text) and labels (target).\n"],"metadata":{"id":"1pD5PjoTTZdX"}},{"cell_type":"code","source":["X_train = train_df['text']\n","y_train = train_df['label']\n","X_test = test_df['text']\n","y_test = test_df['label']"],"metadata":{"id":"VM8rZ2x7KjqE","executionInfo":{"status":"ok","timestamp":1738289525631,"user_tz":-345,"elapsed":366,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess text data\n"],"metadata":{"id":"uQNmNT79TgEL"}},{"cell_type":"code","source":["train_corpus = [text.split() for text in X_train]\n","test_corpus = [text.split() for text in X_test]\n"],"metadata":{"id":"aonIYcXpKp4y","executionInfo":{"status":"ok","timestamp":1738289529692,"user_tz":-345,"elapsed":1030,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Train Word2Vec model\n"],"metadata":{"id":"6mtj5c2-TpZV"}},{"cell_type":"code","source":["w2v_model = Word2Vec(\n","    sentences=train_corpus,  # The input corpus, where each sentence is tokenized into a list of words.\n","    vector_size=100,         # The dimensionality of the word vectors (size of each word embedding).\n","    window=5,                # The maximum distance between the current and predicted word in a sentence (context window).\n","    min_count=2,             # Ignores words that appear less than 2 times in the corpus.\n","    workers=4,               # Number of worker threads used for training (parallelism).\n","    sg=0                     # Specifies the training algorithm: 0 for CBOW (Continuous Bag of Words), 1 for Skip-gram.\n",")"],"metadata":{"id":"kvrCPWm2KshX","executionInfo":{"status":"ok","timestamp":1738289559595,"user_tz":-345,"elapsed":28802,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Save the Word2Vec model"],"metadata":{"id":"y5bgV140Bm1l"}},{"cell_type":"code","source":["# Save the Word2Vec model\n","w2v_model.save(\"word2vec_model.model\")\n","\n"],"metadata":{"id":"Jfv70tf8Bdiu","executionInfo":{"status":"ok","timestamp":1738289635027,"user_tz":-345,"elapsed":639,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Function to convert a corpus of tokenized sentences into vectors using a pre-trained Word2Vec model.\n"],"metadata":{"id":"Dzm28kSAU2h_"}},{"cell_type":"code","source":["# Function to create text embeddings by averaging word vectors\n","def text_to_vector(corpus, model):\n","    vectors = []\n","    for words in corpus:\n","        word_vecs = [model.wv[word] for word in words if word in model.wv]\n","        if len(word_vecs) > 0:\n","            vectors.append(np.mean(word_vecs, axis=0))\n","        else:\n","            vectors.append(np.zeros(model.vector_size))\n","    return np.array(vectors)"],"metadata":{"id":"9zFgEwnsKxIn","executionInfo":{"status":"ok","timestamp":1738289636253,"user_tz":-345,"elapsed":3,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["- The function handles sentences by averaging the Word2Vec embeddings of words in each sentence.\n","- If a sentence contains no words present in the Word2Vec model, a zero vector is used as a placeholder.\n","- The output is a NumPy array where each row corresponds to the vector representation of a sentence."],"metadata":{"id":"Gj6IUjTyU5UP"}},{"cell_type":"markdown","source":["# Vectorize train and test data\n"],"metadata":{"id":"UjrbhZwXVXeJ"}},{"cell_type":"code","source":["X_train_vectors = text_to_vector(train_corpus, w2v_model)\n","X_test_vectors = text_to_vector(test_corpus, w2v_model)\n"],"metadata":{"id":"6WIWE15qK1fI","executionInfo":{"status":"ok","timestamp":1738289646634,"user_tz":-345,"elapsed":9219,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Normalize feature vectors for models like SVM"],"metadata":{"id":"eCF9OjCEAXqn"}},{"cell_type":"code","source":["scaler = MinMaxScaler()\n","X_train_vectors = scaler.fit_transform(X_train_vectors)\n","X_test_vectors = scaler.transform(X_test_vectors)"],"metadata":{"id":"5kmjTVxj5X1W","executionInfo":{"status":"ok","timestamp":1738289646634,"user_tz":-345,"elapsed":8,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["joblib.dump(scaler, 'minmax_scaler.joblib')  # Save the fitted scaler\n"],"metadata":{"id":"5pTOoxT_KASk","executionInfo":{"status":"ok","timestamp":1738289646635,"user_tz":-345,"elapsed":8,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}},"outputId":"05b69c15-72d9-4f5b-e483-e97ba308cc91","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['minmax_scaler.joblib']"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Initialize models\n"],"metadata":{"id":"DDAOoK_IVa3b"}},{"cell_type":"code","source":["xgb_model = XGBClassifier(eval_metric='logloss', random_state=47)\n","svm_model = SVC(probability=True)\n","nb_model = MultinomialNB()\n","rf_model = RandomForestClassifier(random_state=47)"],"metadata":{"id":"eJO2nYKoK41f","executionInfo":{"status":"ok","timestamp":1738289646635,"user_tz":-345,"elapsed":5,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["models = {\n","    'XGBoost': xgb_model,\n","    'SVM': svm_model,\n","    'Naive Bayes': nb_model,\n","    'Random Forest': rf_model\n","}"],"metadata":{"id":"3COSJGGWK7ay","executionInfo":{"status":"ok","timestamp":1738289646635,"user_tz":-345,"elapsed":5,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Train and evaluate models\n"],"metadata":{"id":"HPPA4SIVVx6z"}},{"cell_type":"code","source":["results = []\n","\n","for model_name, model in models.items():\n","    # Train model\n","    model.fit(X_train_vectors, y_train)\n","\n","    # Predict on test data\n","    y_pred = model.predict(X_test_vectors)\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","\n","    # Save the model using joblib\n","    joblib.dump(model, f\"{model_name}_model.joblib\")\n","\n","    results.append({\n","        'Model': model_name,\n","        'Accuracy': accuracy,\n","        'Precision': precision,\n","        'Recall': recall,\n","        'F1 Score': f1\n","    })\n","\n"],"metadata":{"id":"xI0bQudm5Ode","executionInfo":{"status":"ok","timestamp":1738289673369,"user_tz":-345,"elapsed":26738,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Display results\n"],"metadata":{"id":"b9YQufcfV1vr"}},{"cell_type":"code","source":["results_df = pd.DataFrame(results)\n","print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0YMRgqQi4QiY","executionInfo":{"status":"ok","timestamp":1738289685941,"user_tz":-345,"elapsed":663,"user":{"displayName":"Nisha Pokharel","userId":"14609158184766218401"}},"outputId":"302a5b54-33f2-4808-f4c2-f20c75591b7d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["           Model  Accuracy  Precision    Recall  F1 Score\n","0        XGBoost  0.957137   0.944631  0.970690  0.957483\n","1            SVM  0.960566   0.956410  0.964655  0.960515\n","2    Naive Bayes  0.720960   0.677105  0.838793  0.749326\n","3  Random Forest  0.945135   0.923645  0.969828  0.946173\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZSSldxRnH2ID"},"execution_count":null,"outputs":[]}]}